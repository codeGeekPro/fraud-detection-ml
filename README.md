# ğŸ” DÃ©tection de Fraudes Bancaires avec Machine Learning

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Coverage](https://img.shields.io/badge/coverage-80%25-brightgreen.svg)](https://github.com/username/fraud-detection-ml)

## ğŸ“‹ Description

SystÃ¨me de dÃ©tection de fraudes bancaires basÃ© sur le Machine Learning, utilisant des algorithmes avancÃ©s (Random Forest et XGBoost) pour identifier automatiquement les transactions frauduleuses. Le projet met l'accent sur la gestion efficace des donnÃ©es dÃ©sÃ©quilibrÃ©es et l'interprÃ©tabilitÃ© des rÃ©sultats.

Le systÃ¨me intÃ¨gre des techniques avancÃ©es de feature engineering temporel, une gestion robuste des valeurs aberrantes, et une optimisation automatique des hyperparamÃ¨tres. Le pipeline de donnÃ©es est entiÃ¨rement automatisÃ©, de l'ingestion Ã  la prÃ©diction.

### ğŸ¯ CaractÃ©ristiques Principales

- **Preprocessing AvancÃ©**
  - Normalisation robuste des features numÃ©riques
  - Gestion intelligente des valeurs manquantes
  - Exclusion automatique des colonnes sensibles du preprocessing

- **Feature Engineering SophistiquÃ©**
  - Features temporelles (heure, jour, mois)
  - Z-score et dÃ©viations par montant
  - Analyse de frÃ©quence des transactions
  - Scores de risque basÃ©s sur l'historique

- **Gestion du DÃ©sÃ©quilibre**
  - Technique SMOTE pour le rÃ©Ã©chantillonnage
  - Validation stratifiÃ©e pour prÃ©server les proportions
  - MÃ©triques adaptÃ©es aux classes dÃ©sÃ©quilibrÃ©es

- **Performance et Production**
  - Pipeline de donnÃ©es automatisÃ©
  - API REST pour les prÃ©dictions en temps rÃ©el
  - Sauvegarde des transformations pour la production
  - Monitoring des performances

## ğŸš€ Installation

1. Clonez le repository :
```bash
git clone https://github.com/codeGeekPro/fraud-detection-ml.git
cd fraud-detection-ml
```

2. CrÃ©ez un environnement virtuel :
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt
```

4. PrÃ©parez l'environnement :
```bash
# CrÃ©ez les dossiers nÃ©cessaires
mkdir -p data/raw data/processed models/trained logs

# TÃ©lÃ©chargez le dataset (si vous avez Kaggle CLI configurÃ©)
kaggle datasets download -d mlg-ulb/creditcardfraud -p data/raw/
unzip data/raw/creditcardfraud.zip -d data/raw/
```

5. Configurez le projet :
```bash
# VÃ©rifiez et ajustez la configuration dans config/config.yaml
# Les paramÃ¨tres par dÃ©faut sont optimisÃ©s pour les performances

## ğŸ’» Structure du Projet

fraud-detection-ml/
â”œâ”€â”€ config/                 # Fichiers de configuration
â”‚   â””â”€â”€ config.yaml        # Configuration centralisÃ©e
â”œâ”€â”€ data/                  # DonnÃ©es du projet
â”‚   â”œâ”€â”€ external/         # DonnÃ©es externes complÃ©mentaires
â”‚   â”œâ”€â”€ processed/        # DonnÃ©es prÃ©processÃ©es
â”‚   â””â”€â”€ raw/             # DonnÃ©es brutes
â”œâ”€â”€ logs/                  # Journaux d'exÃ©cution
â”œâ”€â”€ models/                # ModÃ¨les et transformations
â”‚   â”œâ”€â”€ metadata/        # MÃ©tadonnÃ©es des modÃ¨les
â”‚   â””â”€â”€ trained/         # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ notebooks/             # Notebooks Jupyter pour l'analyse
â”‚   â”œâ”€â”€ 01_eda_fraud_analysis.ipynb    # Analyse exploratoire
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb   # DÃ©veloppement features
â”‚   â”œâ”€â”€ 03_model_training.ipynb       # Tests des modÃ¨les
â”‚   â””â”€â”€ 04_model_evaluation.ipynb     # Ã‰valuation dÃ©taillÃ©e
â”œâ”€â”€ scripts/               # Scripts d'exÃ©cution
â”‚   â”œâ”€â”€ run_all.py       # Script principal pour tout lancer
â”‚   â”œâ”€â”€ predict.py       # PrÃ©dictions en production
â”‚   â””â”€â”€ train_models.py  # EntraÃ®nement des modÃ¨les
â”œâ”€â”€ src/                   # Code source principal
â”‚   â”œâ”€â”€ api/             # API REST
â”‚   â”‚   â”œâ”€â”€ app.py      # Application FastAPI
â”‚   â”‚   â””â”€â”€ prediction_service.py
â”‚   â”œâ”€â”€ data/           # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py
â”‚   â”‚   â””â”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ models/         # ImplÃ©mentation modÃ¨les
â”‚   â”‚   â”œâ”€â”€ base_model.py
â”‚   â”‚   â”œâ”€â”€ ensemble_model.py
â”‚   â”‚   â”œâ”€â”€ random_forest_model.py
â”‚   â”‚   â””â”€â”€ xgboost_model.py
â”‚   â””â”€â”€ utils/          # Utilitaires
â”‚       â”œâ”€â”€ helpers.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ visualization.py
â””â”€â”€ tests/                # Tests automatisÃ©s
    â”œâ”€â”€ test_api.py
    â”œâ”€â”€ test_data_processing.py
    â””â”€â”€ test_models.py
```

## ï¿½ Utilisation Rapide

### Script Principal (RecommandÃ©)
```bash
# Pipeline complet en une commande
python scripts/run_all.py --all

# Avec l'API
python scripts/run_all.py --all --api

# VÃ©rification de l'environnement
python scripts/run_all.py --check
```

### Utilisation DÃ©taillÃ©e

#### 1. VÃ©rification de l'Environnement
```bash
python scripts/run_all.py --check
```
VÃ©rifie Python 3.8+, les dÃ©pendances, et les fichiers essentiels.

#### 2. EntraÃ®nement des ModÃ¨les
```bash
python scripts/run_all.py --train
```
Lance l'entraÃ®nement complet avec Random Forest et XGBoost.

#### 3. Ã‰valuation des Performances
```bash
python scripts/run_all.py --evaluate
```
Ã‰value les modÃ¨les et gÃ©nÃ¨re les rapports de performance.

#### 4. Pipeline Complet
```bash
python scripts/run_all.py --all
```
ExÃ©cute entraÃ®nement + Ã©valuation + gÃ©nÃ©ration de rapports.

#### 5. API de PrÃ©diction
```bash
# API seule
python scripts/run_all.py --api

# API sur un port spÃ©cifique
python scripts/run_all.py --api --host 127.0.0.1 --port 8080
```

### Utilisation AvancÃ©e

#### Mode Strict
```bash
python scripts/run_all.py --all --strict
```
ArrÃªte le pipeline en cas d'erreur (utile pour CI/CD).

#### Mode Verbose
```bash
python scripts/run_all.py --all --verbose
```
Affiche tous les dÃ©tails d'exÃ©cution.

#### Combinaisons PersonnalisÃ©es
```bash
# Ã‰valuation seulement
python scripts/run_all.py --evaluate

# EntraÃ®nement + rapport seulement
python scripts/run_all.py --train --report

# Tout sauf l'API
python scripts/run_all.py --all
```

## ï¿½ğŸ“Š Utilisation

### 1. Analyse Exploratoire
Explorez les caractÃ©ristiques des transactions et la distribution des fraudes :
```bash
jupyter notebook notebooks/01_eda_fraud_analysis.ipynb
```

### 2. Feature Engineering
DÃ©veloppez et testez de nouvelles features :
```bash
jupyter notebook notebooks/02_feature_engineering.ipynb
```

### 3. EntraÃ®nement des ModÃ¨les
Lancez l'entraÃ®nement complet avec validation croisÃ©e :
```bash
python scripts/train_models.py
```

### 4. Ã‰valuation des Performances
Analysez les performances dÃ©taillÃ©es des modÃ¨les :
```bash
jupyter notebook notebooks/04_model_evaluation.ipynb
```

### 5. API de PrÃ©diction
Lancez l'API pour les prÃ©dictions en temps rÃ©el :
```bash
python src/api/app.py
```

### 6. Exemple d'Utilisation de l'API
```python
import requests

# PrÃ©parez les donnÃ©es de la transaction
transaction = {
    "amount": 123.45,
    "time": 43200,  # 12:00 (midi)
    "v1": -1.3598071336738172,
    "v2": -0.0727811733098497,
    "v3": 2.536346738618042,
    # ... autres features V1-V28
}

# Envoyez la requÃªte
response = requests.post(
    "http://localhost:8000/predict",
    json={"transaction": transaction}
)

# Analysez la rÃ©ponse
result = response.json()
print(f"ProbabilitÃ© de fraude : {result['fraud_probability']:.2%}")
print(f"PrÃ©diction : {'Frauduleuse' if result['is_fraud'] else 'LÃ©gitime'}")
print(f"Temps de rÃ©ponse : {result['response_time_ms']:.2f}ms")
```

## ğŸ“ˆ Performance

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s en utilisant la validation croisÃ©e Ã  5 plis :

### Random Forest (Meilleur ModÃ¨le)
- Precision-Recall AUC : 0.9999992 Â± 0.0000011
- Excellente gestion des classes dÃ©sÃ©quilibrÃ©es
- Robuste aux outliers

### XGBoost
- Precision-Recall AUC : 0.9999869 Â± 0.0000147
- Performance lÃ©gÃ¨rement infÃ©rieure au Random Forest
- Temps d'entraÃ®nement plus court

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Consultez [CONTRIBUTING.md](CONTRIBUTING.md) pour les directives.

## ï¿½ Technologies UtilisÃ©es

- **Python 3.8+** - Langage de programmation principal
- **scikit-learn** - Algorithmes de ML et preprocessing
- **XGBoost** - ModÃ¨le de boosting
- **pandas** - Manipulation de donnÃ©es
- **numpy** - Calculs numÃ©riques
- **FastAPI** - API REST
- **pytest** - Tests unitaires
- **black** - Formatage de code
- **mypy** - VÃ©rification des types
- **logging** - Journalisation structurÃ©e
- **YAML** - Configuration externalisÃ©e

## ï¿½ğŸ“ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Contact

Code Geek Pro - [GitHub](https://github.com/codeGeekPro)

Lien du projet : [https://github.com/codeGeekPro/fraud-detection-ml](https://github.com/codeGeekPro/fraud-detection-ml)
